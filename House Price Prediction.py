# -*- coding: utf-8 -*-
"""Task-3-Linear Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BqB5IeHhpZGa6UBwQ1tQ7Rwq1oiHK9VE
"""

# task3_solution.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Step 1: Load dataset
data = pd.read_csv("Housing.csv")
print("First 5 rows of the dataset:")
print(data.head())

# Step 2: Preprocess data
data_encoded = pd.get_dummies(data, drop_first=True)

# ----------------------------------
# PART 1: SIMPLE LINEAR REGRESSION
# Using only 'area' to predict 'price'
# ----------------------------------

print("\n--- Simple Linear Regression (area -> price) ---")

X_simple = data[['area']]
y_simple = data['price']

X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_simple, y_simple, test_size=0.2, random_state=42)

simple_lr = LinearRegression()
simple_lr.fit(X_train_s, y_train_s)

y_pred_s = simple_lr.predict(X_test_s)

print("Coefficient:", simple_lr.coef_[0])
print("Intercept:", simple_lr.intercept_)

mae_s = mean_absolute_error(y_test_s, y_pred_s)
mse_s = mean_squared_error(y_test_s, y_pred_s)
r2_s = r2_score(y_test_s, y_pred_s)

print(f"MAE: {mae_s}")
print(f"MSE: {mse_s}")
print(f"R²: {r2_s}")

# Visualize regression line
plt.figure(figsize=(8, 6))
plt.scatter(X_test_s, y_test_s, label='Actual', alpha=0.6)
plt.plot(X_test_s, y_pred_s, color='red', label='Predicted Line')
plt.title("Simple Linear Regression: Area vs Price")
plt.xlabel("Area")
plt.ylabel("Price")
plt.legend()
plt.grid(True)
plt.show()

# ----------------------------------
# PART 2: MULTIPLE LINEAR REGRESSION
# Using all features
# ----------------------------------

print("\n--- Multiple Linear Regression (all features) ---")

X_multi = data_encoded.drop("price", axis=1)
y_multi = data_encoded["price"]

X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)

multi_lr = LinearRegression()
multi_lr.fit(X_train_m, y_train_m)

y_pred_m = multi_lr.predict(X_test_m)

mae_m = mean_absolute_error(y_test_m, y_pred_m)
mse_m = mean_squared_error(y_test_m, y_pred_m)
r2_m = r2_score(y_test_m, y_pred_m)

print("Model Coefficients:")
coeff_df = pd.DataFrame(multi_lr.coef_, X_multi.columns, columns=["Coefficient"])
print(coeff_df)

print(f"\nMAE: {mae_m}")
print(f"MSE: {mse_m}")
print(f"R²: {r2_m}")

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(data_encoded.corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.tight_layout()
plt.show()

# Actual vs Predicted plot
plt.figure(figsize=(8, 6))
plt.scatter(y_test_m, y_pred_m, alpha=0.6, color='purple')
plt.plot([y_test_m.min(), y_test_m.max()], [y_test_m.min(), y_test_m.max()], 'r--')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted (Multiple Regression)")
plt.grid(True)
plt.show()

# Residuals distribution
residuals_m = y_test_m - y_pred_m
plt.figure(figsize=(8, 6))
sns.histplot(residuals_m, kde=True, color='green')
plt.title("Residuals Distribution (Multiple Regression)")
plt.xlabel("Residuals")
plt.grid(True)
plt.show()